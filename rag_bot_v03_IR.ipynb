{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f01b288",
   "metadata": {},
   "source": [
    "![image](img/librarian_bot.png)\n",
    "\n",
    "# RAG bot for investor information\n",
    "\n",
    "Specialized bot focusing on analysing financial documents from Investor Relations webpages. \n",
    "Comes together with a web crawler spider to gather documents quickly.\n",
    "\n",
    "This notebook will create a personal RAG bot. It will use a the ./kb directory to store the files that we want to include in the RAG. Subdirectories will be used to denote categories for the files.\n",
    "**Important: only one level of subdirectories will be used for the categories**\n",
    "\n",
    "It uses LangChain to create and process the RAG pipeline and chat.\n",
    "The vector database persistent sotre is in the ./vdb folder. \n",
    "\n",
    "In this version we use chromadb for the vector store.\n",
    "The store is recreated each run. This is not efficient for large datasets. \n",
    "\n",
    "Future upgrades - To Do (in no particular order): \n",
    "- [x] Create a fully local version for security and privacy (*see v01_local*) <span style=\"color:orange\">\n",
    "        NOTE: will require a fairly advanced LLM to answer questions without losing context. 2-4bn parameters LLM's struggle and tend to hallucinate. Best options are gpt-4o-mini and claude-3.5-haiku.</span>\n",
    "- [x] Fine tune the pdf scraper to handle financial reports better\n",
    "- [x] Create custom retriever for financial information\n",
    "- [x] Add chatbot selection option (Claude - GPT)\n",
    "- [ ] Switch to LangGraph for Conversation Chain. \n",
    "- [ ] Change vector store to lancedb (part of moving to serverless data store in production)\n",
    "- [ ] Add an interface to upload documents in data store - including user-defined metadata tags\n",
    "- [ ] Create persistent data store between runs - only load, chunk and embed changed documents.\n",
    "- [ ] Read data from S3\n",
    "- [ ] Enhance data store with metadata for advanced filtering. When uploading reports from different companies semantic search cannot always accurately distinguish differences and can combine references or results from two different companies in a single response. Also see above for lancedb.\n",
    "- [ ] Multimodality: Process more document data types (e.g. ppt) \n",
    "- [x] Add online search capability - use web crawler tool to crawl a website and create website-specific RAG bot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed87a4da",
   "metadata": {},
   "source": [
    "![image](img/thinking_cyborg.jpg)\n",
    "\n",
    "# Future ideas:\n",
    "\n",
    "1) To avoid context contamination from multiple companies consider setting up a different RAG for each company\n",
    "2) Select companies from dropdown or hamburger menu\n",
    "3) Keep company metadata and RAG registry in a document db (Mongo, DynamoDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dfe8e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: docx2txt in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (0.9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf4llm in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (0.0.27)\n",
      "Requirement already satisfied: pymupdf>=1.26.3 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pymupdf4llm) (1.26.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (0.3.24)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.65 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain-openai) (0.3.73)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.86.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain-openai) (1.88.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-openai) (0.3.45)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-openai) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-openai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-openai) (4.14.0)\n",
      "Requirement already satisfied: packaging>=23.2 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-openai) (24.2)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-openai) (2.11.7)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.65->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.86.0->langchain-openai) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain-openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain-openai) (0.4.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-openai) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-openai) (0.23.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-anthropic in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (0.3.18)\n",
      "Requirement already satisfied: anthropic<1,>=0.60.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain-anthropic) (0.61.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain-anthropic) (0.3.73)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain-anthropic) (2.11.7)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from anthropic<1,>=0.60.0->langchain-anthropic) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from anthropic<1,>=0.60.0->langchain-anthropic) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from anthropic<1,>=0.60.0->langchain-anthropic) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from anthropic<1,>=0.60.0->langchain-anthropic) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from anthropic<1,>=0.60.0->langchain-anthropic) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from anthropic<1,>=0.60.0->langchain-anthropic) (4.14.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from anyio<5,>=3.5.0->anthropic<1,>=0.60.0->langchain-anthropic) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from httpx<1,>=0.25.0->anthropic<1,>=0.60.0->langchain-anthropic) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from httpx<1,>=0.25.0->anthropic<1,>=0.60.0->langchain-anthropic) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic<1,>=0.60.0->langchain-anthropic) (0.16.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain-anthropic) (0.3.45)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain-anthropic) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain-anthropic) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain-anthropic) (6.0.2)\n",
      "Requirement already satisfied: packaging>=23.2 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain-anthropic) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain-anthropic) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-anthropic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-anthropic) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-anthropic) (0.4.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.72->langchain-anthropic) (3.10.18)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.72->langchain-anthropic) (2.32.4)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.72->langchain-anthropic) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.72->langchain-anthropic) (0.23.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.72->langchain-anthropic) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.72->langchain-anthropic) (2.5.0)\n"
     ]
    }
   ],
   "source": [
    "# These were necessary as langchain does not install them by default\n",
    "# !pip install pypdf\n",
    "# !pip install pdfminer.six\n",
    "# !pip install python-docx\n",
    "!pip install docx2txt\n",
    "!pip install pymupdf4llm\n",
    "!pip install langchain-openai\n",
    "!pip install langchain-anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "193171c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "\n",
    "# imports for langchain, plotly and Chroma\n",
    "# plotly is commented out, as it is not used in the current code\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader, PDFMinerLoader, Docx2txtLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_anthropic import Anthropic\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "#import matplotlib.pyplot as plt\n",
    "#from sklearn.manifold import TSNE\n",
    "#import numpy as np\n",
    "#import plotly.graph_objects as go\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d22d2e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_MODEL = \"gpt-4o-mini\"\n",
    "ANTHROPIC_MODEL = \"claude-3-5-haiku-20241022\"\n",
    "db_name = \"vdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc23bf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(override=True)\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')\n",
    "os.environ['ANTHROPIC_API_KEY'] = os.getenv('ANTHROPIC_API_KEY', 'your-key-if-not-using-env')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0103ef35",
   "metadata": {},
   "source": [
    "## Loading the documents\n",
    "\n",
    "In the code below we read in the KB documents and create the vector store. \n",
    "We will be adding PDF documents, Word documents and text/markdown documents. \n",
    "Each document has its own loader, which we are calling separately through DirectoryLoader.\n",
    "For PDF we implement custom loader to manage financial data. \n",
    "\n",
    "At the end, we are combining the results, and then start splitting the documents using the Recursive Character Text Splitter.\n",
    "\n",
    "This approach is not optimal for financial tables.\n",
    "TO DO:\n",
    " - [x] Replace splitter with better technique that preserves tables.\n",
    " - [x] Replace PDF Reader with pymupdf4llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "918cbbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for EU financial reporting (read from PDF)\n",
    "# We're using pymupdf4llm for better handling of financial reports\n",
    "# This function does not utilize a loader class, but directly processes the PDF file\n",
    "# It extracts financial sections and returns them as Document objects\\\n",
    "\n",
    "import pymupdf4llm\n",
    "from langchain.schema import Document\n",
    "import re\n",
    "import string\n",
    "from pathlib import Path\n",
    "\n",
    "def extract_eu_financial_reports(pdf_path):\n",
    "    \"\"\"\n",
    "    Extracts financial sections from an EU financial report PDF using pymupdf4llm.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): Path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "        list[Document]: A list of LangChain Document objects, each representing a detected financial section\n",
    "                        (e.g., income statement, balance sheet, cash flow statement, etc.) with associated metadata.\n",
    "\n",
    "    The function processes the PDF, detects section headers based on common financial report section names,\n",
    "    and splits the content accordingly. Each Document contains the section text and metadata including section name,\n",
    "    content type, source file, and page range.\n",
    "    \"\"\"\n",
    "    md_text = pymupdf4llm.to_markdown(\n",
    "        pdf_path,\n",
    "        page_chunks=True,  # Preserve page boundaries\n",
    "        write_images=False,\n",
    "        embed_images=False\n",
    "    )\n",
    "    \n",
    "    # EU financial reports have predictable structures\n",
    "    financial_sections = [\n",
    "        \"consolidated income statement\", \"profit and loss\", \"p&l\", \"remuneration report\",\n",
    "        \"balance sheet\", \"cash flow statement\", \"statement of financial position\",\n",
    "        \"notes to the consolidated financial statements\", \"segment reporting\",\n",
    "        \"risk management\", \"capital adequacy\", \"basel\", \"ifrs\", \"regulatory capital\", \"income statement\"\n",
    "    ]\n",
    "    \n",
    "    documents = []\n",
    "    current_section = None\n",
    "    current_content = \"\"\n",
    "    start_page = 1\n",
    "    \n",
    "    for page_dict in md_text:\n",
    "        # Extract the actual text content from the dictionary\n",
    "        page_content = page_dict.get(\"text\", \"\")\n",
    "        page_num = page_dict.get(\"page\", start_page)\n",
    "        \n",
    "        print(f\"Processing page: {page_num}\")\n",
    "\n",
    "        # Detect financial section headers\n",
    "        content_lower = page_content.lower()\n",
    "        detected_section = None\n",
    "        \n",
    "        for section in financial_sections:\n",
    "            if section in content_lower:\n",
    "                detected_section = section\n",
    "                break\n",
    "        \n",
    "        # Process section changes\n",
    "        if detected_section and detected_section != current_section:\n",
    "            if current_content:\n",
    "                # Save previous section\n",
    "                documents.append(Document(\n",
    "                    page_content=current_content.strip(),\n",
    "                    metadata={\n",
    "                        \"content_type\": \"financial_statement\",\n",
    "                        \"section\": current_section or \"general\",\n",
    "                        \"source\": pdf_path,\n",
    "                        \"pages\": f\"{start_page}-{page_num-1}\"\n",
    "                    }\n",
    "                ))\n",
    "            current_section = detected_section\n",
    "            current_content = page_content\n",
    "        else:\n",
    "            current_content += \"\\n---\\n\" + page_content\n",
    "    \n",
    "    # Handle final section\n",
    "    if current_content:\n",
    "        documents.append(Document(\n",
    "            page_content=current_content.strip(),\n",
    "            metadata={\n",
    "                \"content_type\": \"financial_statement\",\n",
    "                \"section\": current_section or \"general\",\n",
    "                \"source\": pdf_path,\n",
    "                \"pages\": f\"{start_page}-{page_num}\"\n",
    "            }\n",
    "        )) \n",
    "    \n",
    "    return documents\n",
    "\n",
    "# Utility functions for loading documents from a folder\n",
    "def load_eu_financial_reports_from_directory(directory_path: str, glob_pattern: str = \"*.pdf\"):\n",
    "    \"\"\"\n",
    "    Load and process all EU financial reports from a directory.\n",
    "\n",
    "    Args:\n",
    "        directory_path (str): Path to the directory containing PDF files\n",
    "        glob_pattern (str, optional): Pattern to match PDF files. Defaults to \"*.pdf\"\n",
    "\n",
    "    Returns:\n",
    "        list[Document]: A list of LangChain Document objects containing the extracted financial sections\n",
    "                       from all successfully processed PDFs in the directory.\n",
    "\n",
    "    The function iterates through PDF files in the specified directory that match the glob pattern,\n",
    "    processes each file using extract_eu_financial_reports(), and combines the results into a single list.\n",
    "    Files that cannot be processed are skipped with an error message printed to stdout.\n",
    "    \"\"\"\n",
    "    all_documents = []\n",
    "    directory = Path(directory_path)\n",
    "    \n",
    "    for pdf_file in directory.glob(glob_pattern):\n",
    "        try:\n",
    "            print(f\"Processing {pdf_file}...\")\n",
    "            documents = extract_eu_financial_reports(str(pdf_file))\n",
    "            all_documents.extend(documents)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {pdf_file}: {e}\")\n",
    "    \n",
    "    return all_documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f20fd20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 folders in the knowledge base.\n",
      "Loading documents from folder: kb/eurobankholdings.gr\n",
      "Processing kb/eurobankholdings.gr/etisia-oikonomiki-ekthesi-en-2024.pdf...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     29\u001b[39m docx_loader = DirectoryLoader(folder, glob=\u001b[33m\"\u001b[39m\u001b[33m**/*.docx\u001b[39m\u001b[33m\"\u001b[39m, loader_cls=Docx2txtLoader)\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# document doc_type is used to identify the type of document\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Load documents from PDF, text and word files and combine the results\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m pdf_docs += \u001b[43mload_eu_financial_reports_from_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(pdf_docs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m PDF documents from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     34\u001b[39m text_docs = txt_loader.load() + md_loader.load()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 118\u001b[39m, in \u001b[36mload_eu_financial_reports_from_directory\u001b[39m\u001b[34m(directory_path, glob_pattern)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    117\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpdf_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m     documents = \u001b[43mextract_eu_financial_reports\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpdf_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m     all_documents.extend(documents)\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mextract_eu_financial_reports\u001b[39m\u001b[34m(pdf_path)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mextract_eu_financial_reports\u001b[39m(pdf_path):\n\u001b[32m     13\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[33;03m    Extracts financial sections from an EU financial report PDF using pymupdf4llm.\u001b[39;00m\n\u001b[32m     15\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m \u001b[33;03m    content type, source file, and page range.\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     md_text = \u001b[43mpymupdf4llm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_markdown\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpage_chunks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Preserve page boundaries\u001b[39;49;00m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwrite_images\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[43membed_images\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m     \u001b[38;5;66;03m# EU financial reports have predictable structures\u001b[39;00m\n\u001b[32m     35\u001b[39m     financial_sections = [\n\u001b[32m     36\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mconsolidated income statement\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mprofit and loss\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mp&l\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mremuneration report\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     37\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbalance sheet\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcash flow statement\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstatement of financial position\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     38\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mnotes to the consolidated financial statements\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msegment reporting\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     39\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrisk management\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcapital adequacy\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mbasel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mifrs\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mregulatory capital\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mincome statement\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     40\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llms/lib/python3.11/site-packages/pymupdf4llm/helpers/pymupdf_rag.py:1202\u001b[39m, in \u001b[36mto_markdown\u001b[39m\u001b[34m(doc, pages, hdr_info, write_images, embed_images, ignore_images, ignore_graphics, detect_bg_color, image_path, image_format, image_size_limit, filename, force_text, page_chunks, page_separators, margins, dpi, page_width, page_height, table_strategy, graphics_limit, fontsize_limit, ignore_code, extract_words, show_progress, use_glyphs, ignore_alpha)\u001b[39m\n\u001b[32m   1200\u001b[39m     pages = ProgressBar(pages)\n\u001b[32m   1201\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pno \u001b[38;5;129;01min\u001b[39;00m pages:\n\u001b[32m-> \u001b[39m\u001b[32m1202\u001b[39m     parms = \u001b[43mget_page_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1203\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpno\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmargins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtextflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFILENAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIGNORE_IMAGES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIGNORE_GRAPHICS\u001b[49m\n\u001b[32m   1204\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1205\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m page_chunks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m   1206\u001b[39m         document_output += parms.md_string\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llms/lib/python3.11/site-packages/pymupdf4llm/helpers/pymupdf_rag.py:973\u001b[39m, in \u001b[36mto_markdown.<locals>.get_page_output\u001b[39m\u001b[34m(doc, pno, margins, textflags, FILENAME, IGNORE_IMAGES, IGNORE_GRAPHICS)\u001b[39m\n\u001b[32m    970\u001b[39m parms.annot_rects = [a.rect \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m page.annots()]\n\u001b[32m    972\u001b[39m \u001b[38;5;66;03m# make a TextPage for all later extractions\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m973\u001b[39m parms.textpage = \u001b[43mpage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_textpage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtextflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclip\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[38;5;66;03m# extract images on page\u001b[39;00m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m IGNORE_IMAGES:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llms/lib/python3.11/site-packages/pymupdf/__init__.py:9511\u001b[39m, in \u001b[36mPage.get_textpage\u001b[39m\u001b[34m(self, clip, flags, matrix)\u001b[39m\n\u001b[32m   9509\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_rotation(\u001b[32m0\u001b[39m)\n\u001b[32m   9510\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m9511\u001b[39m     textpage = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_textpage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   9512\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   9513\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m old_rotation != \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llms/lib/python3.11/site-packages/pymupdf/__init__.py:8050\u001b[39m, in \u001b[36mPage._get_textpage\u001b[39m\u001b[34m(self, clip, flags, matrix)\u001b[39m\n\u001b[32m   8048\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_textpage\u001b[39m(\u001b[38;5;28mself\u001b[39m, clip=\u001b[38;5;28;01mNone\u001b[39;00m, flags=\u001b[32m0\u001b[39m, matrix=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   8049\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m g_use_extra:\n\u001b[32m-> \u001b[39m\u001b[32m8050\u001b[39m         ll_tpage = \u001b[43mextra\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpage_get_textpage\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   8051\u001b[39m         tpage = mupdf.FzStextPage(ll_tpage)\n\u001b[32m   8052\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m tpage\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llms/lib/python3.11/site-packages/pymupdf/extra.py:195\u001b[39m, in \u001b[36mpage_get_textpage\u001b[39m\u001b[34m(_self, clip, flags, matrix)\u001b[39m\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpage_get_textpage\u001b[39m(_self, clip, flags, matrix):\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_extra\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpage_get_textpage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Read in documents using LangChain's loaders\n",
    "# Take everything in all the sub-folders of our knowledgebase\n",
    "\n",
    "folders = glob.glob(\"kb/*\")\n",
    "print(f\"Found {len(folders)} folders in the knowledge base.\")\n",
    "\n",
    "def add_metadata(doc, doc_type):\n",
    "    doc.metadata[\"doc_type\"] = doc_type\n",
    "    return doc\n",
    "\n",
    "# For text files\n",
    "text_loader_kwargs = {'encoding': 'utf-8'}\n",
    "\n",
    "documents = []\n",
    "pdf_docs = []\n",
    "for folder in folders:\n",
    "    print(f\"Loading documents from folder: {folder}\")\n",
    "    doc_type = os.path.basename(folder)\n",
    "    # PDF Loader\n",
    "    # We're not using the PDFMinerLoader as it does not handle EU financial reports well.\n",
    "    # Instead, we use our custom extract_eu_financial_reports function.\n",
    "    # Uncomment the next line if you want to use the standard loader for PDF files\n",
    "    # pdf_loader = DirectoryLoader(folder, glob=\"**/*.pdf\", loader_cls=extract_eu_financial_reports)\n",
    "    # Text loaders\n",
    "    txt_loader = DirectoryLoader(folder, glob=\"**/*.txt\", loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)\n",
    "    md_loader = DirectoryLoader(folder, glob=\"**/*.md\", loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)\n",
    "    # Load MS Word documents - UnstructuredWordDocumentLoader does not play well with numpy > 1.24.0, and we use Docx2txtLoader instead. \n",
    "    # doc_loader = DirectoryLoader(folder, glob=\"**/*.doc\", loader_cls=UnstructuredWordDocumentLoader)\n",
    "    docx_loader = DirectoryLoader(folder, glob=\"**/*.docx\", loader_cls=Docx2txtLoader)\n",
    "    # document doc_type is used to identify the type of document\n",
    "    # Load documents from PDF, text and word files and combine the results\n",
    "    pdf_docs += load_eu_financial_reports_from_directory(folder)\n",
    "    print(f\"Loaded {len(pdf_docs)} PDF documents from {folder}\")\n",
    "    text_docs = txt_loader.load() + md_loader.load()\n",
    "    print(f\"Loaded {len(text_docs)} text documents from {folder}\")\n",
    "    word_docs = docx_loader.load()\n",
    "    print(f\"Loaded {len(word_docs)} Word documents from {folder}\")\n",
    "    # PDF documents are processed separately, so we combine them with text and word documents\n",
    "    # If no PDF documents are found, we still want to process text and word documents\n",
    "    folder_docs = text_docs + word_docs\n",
    "    \n",
    "    # Add metadata to each document\n",
    "    if not folder_docs:\n",
    "        print(f\"No documents found in folder: {folder}\")\n",
    "        continue\n",
    "    documents.extend([add_metadata(doc, doc_type) for doc in folder_docs])\n",
    "\n",
    "# Split the text documents into chunks and combine with the pdf documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents) + pdf_docs\n",
    "\n",
    "# Print out some basic info for the loaded documents and chunks\n",
    "print(f\"Total number of documents: {len(documents)}\")\n",
    "print(f\"Total number of chunks: {len(chunks)}\")\n",
    "print(f\"Document types found: {set(doc.metadata['doc_type'] for doc in documents)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749ad5d8",
   "metadata": {},
   "source": [
    "## Vector Store\n",
    "\n",
    "We use Chromadb for vector store.\n",
    "\n",
    "Same code as the one in the lesson notebook, minus the visualization part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc70e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6t/cgrwwgfx4yq_qhc99qn0xtbr0000gn/T/ipykernel_49091/2950390889.py:7: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\") # A bit slower, but better than all-MiniLM-L6-v2 for financial documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created with 149 documents\n",
      "There are 149 vectors with 768 dimensions in the vector store\n"
     ]
    }
   ],
   "source": [
    "#embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# If you would rather use the free Vector Embeddings from HuggingFace sentence-transformers\n",
    "# Then replace embeddings = OpenAIEmbeddings()\n",
    "# with:\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\") # A bit slower, but better than all-MiniLM-L6-v2 for financial documents\n",
    "\n",
    "# Delete if already exists\n",
    "\n",
    "if os.path.exists(db_name):\n",
    "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()\n",
    "\n",
    "# Create vectorstore\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_name)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")\n",
    "\n",
    "# Let's investigate the vectors\n",
    "\n",
    "collection = vectorstore._collection\n",
    "count = collection.count()\n",
    "\n",
    "sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\"embeddings\"][0]\n",
    "dimensions = len(sample_embedding)\n",
    "print(f\"There are {count:,} vectors with {dimensions:,} dimensions in the vector store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9af1d32",
   "metadata": {},
   "source": [
    "## LangChain\n",
    "Create Langchain chat, memory and retrievers.\n",
    "\n",
    "Trying a number of LLM's for ollama. They are not very good at sortingo out the relevant information from financial documents - they do provide results, but tend to be overly chatty and especially the specific numbers can be hallucinated or taken out of context. \n",
    "\n",
    "GPT-4o-mini provided much more accurate answers to specific questions, even with huggingface's embeddings for the vector store. \n",
    "\n",
    "Implemented (with Claude's help) a custom retriever and prompt to focus on financial statement analysis.\n",
    "\n",
    "### OpenAI rate limits\n",
    "*Note*: If using OpenAI's embeddings, there's a limit of 300K tokens per request. This requires special handling when calling Chroma.from_documents.\n",
    "###TO DO:\n",
    "- [ ] Add rate limiter for encoding documents and encode in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f75e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specialized Retriever for consolidated financials\n",
    "\n",
    "from langchain.schema import BaseRetriever, Document\n",
    "from typing import List\n",
    "\n",
    "from langchain.vectorstores.base import VectorStoreRetriever\n",
    "\n",
    "class EUFinancialRetriever(VectorStoreRetriever):\n",
    "    def _get_relevant_documents(self, query: str, *, run_manager=None) -> List[Document]:\n",
    "        query_lower = query.lower()\n",
    "        k = self.search_kwargs.get(\"k\", 5)\n",
    "        \n",
    "        # Section-aware search logic\n",
    "        section_queries = {\n",
    "            'income': ['income', 'revenue', 'profit', 'earnings'],\n",
    "            'balance': ['balance', 'assets', 'liabilities', 'equity'],\n",
    "            'cash': ['cash flow', 'operating cash', 'free cash']\n",
    "        }\n",
    "        \n",
    "        for section, terms in section_queries.items():\n",
    "            if any(term in query_lower for term in terms):\n",
    "                try:\n",
    "                    return self.vectorstore.similarity_search(\n",
    "                        query, k=k, filter={\"section\": section}\n",
    "                    )\n",
    "                except:\n",
    "                    break\n",
    "        \n",
    "        # Fallback to standard search\n",
    "        return self.vectorstore.similarity_search(query, k=k)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca30d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specialized prompt for the retriever\n",
    "\n",
    "financial_prompt = \"\"\"\n",
    "You are analyzing EU bank and corporate financial statements. When answering:\n",
    "\n",
    "1. For numerical data, ALWAYS cite the specific financial statement section\n",
    "2. Consider regulatory context (IFRS, Basel III for banks)\n",
    "3. Note if data spans multiple periods or segments\n",
    "4. Highlight any footnotes or adjustments mentioned\n",
    "5. Be precise about currency and units (EUR millions, thousands, etc.)\n",
    "\n",
    "Context from financial statements:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "# Updated chain with financial-aware prompt\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=financial_prompt\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2360006e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6t/cgrwwgfx4yq_qhc99qn0xtbr0000gn/T/ipykernel_49091/1872829341.py:8: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True, output_key='answer')\n"
     ]
    }
   ],
   "source": [
    "# create a new Chat with OpenAI\n",
    "#llm = ChatOpenAI(temperature=0.7, model_name=MODEL)\n",
    "\n",
    "# Alternative - if you'd like to use Ollama locally, uncomment this line instead\n",
    "#llm = ChatOpenAI(temperature=0.7, model_name='gemma3:4b', base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "# set up the conversation memory for the chat\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True, output_key='answer')\n",
    "\n",
    "# the retriever is an abstraction over the VectorStore that will be used during RAG\n",
    "retriever = EUFinancialRetriever(\n",
    "    vectorstore=vectorstore, \n",
    "    search_kwargs={\"k\": 5}\n",
    ")\n",
    "# putting it together: set up the conversation chain with the GPT 3.5 LLM, the vector store and memory\n",
    "\n",
    "# Initialize chains outside the chat function\n",
    "chains = {}\n",
    "\n",
    "def get_or_create_chain(model_name):\n",
    "    if model_name not in chains:\n",
    "        if model_name == OPENAI_MODEL:\n",
    "            llm = ChatOpenAI(temperature=0.7, model_name=OPENAI_MODEL)\n",
    "        elif model_name == ANTHROPIC_MODEL:\n",
    "            # If using Anthropic, ensure you have the langchain-anthropic package installed\n",
    "            from langchain_anthropic import ChatAnthropic\n",
    "            llm = ChatAnthropic(temperature=0.7, model_name=ANTHROPIC_MODEL)\n",
    "        \n",
    "        chains[model_name] = ConversationalRetrievalChain.from_llm(\n",
    "            llm=llm, \n",
    "            retriever=retriever, \n",
    "            memory=memory, \n",
    "            combine_docs_chain_kwargs={\"prompt\": prompt},\n",
    "            return_source_documents=True\n",
    "        )\n",
    "    return chains[model_name]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a21bb3",
   "metadata": {},
   "source": [
    "## UI part\n",
    "Create Gradio interface\n",
    "\n",
    "Simple built-in chat interface\n",
    "\n",
    "###To Do: \n",
    "- [x] Add model selector for Claude 3.5 Haiku\n",
    "- [x] Update interface to handle sources (with **return_source_documents=True**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfe7d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Wrapping that in a function\n",
    "\n",
    "def chat(question, history, dropdown_value):\n",
    "    conversation_chain = get_or_create_chain(dropdown_value)\n",
    "    result = conversation_chain.invoke({\"question\": question})\n",
    "    answer = result[\"answer\"]\n",
    "    source_docs = result.get(\"source_documents\", [])\n",
    "    if source_docs:\n",
    "        sources_text = \"\\n\\n**Sources:**\\n\"\n",
    "        for i, doc in enumerate(source_docs, 1):\n",
    "            # Extracting source and page information from the document metadata\n",
    "            # If the document has a 'source' metadata field, use it; otherwise, default\n",
    "            source = doc.metadata.get('source', 'Unknown source')\n",
    "            page = doc.metadata.get('pages', '')\n",
    "            \n",
    "            if page:\n",
    "                sources_text += f\"{i}. {source} (Page {page})\\n\"\n",
    "            else:\n",
    "                sources_text += f\"{i}. {source}\\n\"\n",
    "        return answer + sources_text\n",
    "    else: \n",
    "        return answer\n",
    "\n",
    "# And in Gradio:\n",
    "\n",
    "view = gr.ChatInterface(chat, type=\"messages\",\n",
    "    additional_inputs=[gr.Dropdown([OPENAI_MODEL, ANTHROPIC_MODEL], label=\"Select model\", value=OPENAI_MODEL)]).launch(inbrowser=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
