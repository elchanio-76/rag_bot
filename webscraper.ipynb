{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1af24b2",
   "metadata": {},
   "source": [
    "# Website scraper using scrappy\n",
    "\n",
    "Will crawl a site and scrape documents. \n",
    "documents are saved in kb/web\n",
    "\n",
    "To Do:\n",
    "- [ ] Move this to a standalone Python application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05572c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016db80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: Resetting dropped connection: huggingface.co\n",
      "DEBUG: connect_tcp.started host='api.gradio.app' port=443 local_address=None timeout=3 socket_options=None\n",
      "DEBUG: connect_tcp.started host='127.0.0.1' port=7870 local_address=None timeout=None socket_options=None\n",
      "DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1110ab790>\n",
      "DEBUG: send_request_headers.started request=<Request [b'GET']>\n",
      "DEBUG: send_request_headers.complete\n",
      "DEBUG: send_request_body.started request=<Request [b'GET']>\n",
      "DEBUG: send_request_body.complete\n",
      "DEBUG: receive_response_headers.started request=<Request [b'GET']>\n",
      "DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Sun, 20 Jul 2025 09:21:40 GMT'), (b'server', b'uvicorn'), (b'content-length', b'4'), (b'content-type', b'application/json')])\n",
      "INFO: HTTP Request: GET http://127.0.0.1:7870/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "DEBUG: receive_response_body.started request=<Request [b'GET']>\n",
      "DEBUG: receive_response_body.complete\n",
      "DEBUG: response_closed.started\n",
      "DEBUG: response_closed.complete\n",
      "DEBUG: close.started\n",
      "DEBUG: close.complete\n",
      "DEBUG: connect_tcp.started host='127.0.0.1' port=7870 local_address=None timeout=3 socket_options=None\n",
      "DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11112f810>\n",
      "DEBUG: send_request_headers.started request=<Request [b'HEAD']>\n",
      "DEBUG: send_request_headers.complete\n",
      "DEBUG: send_request_body.started request=<Request [b'HEAD']>\n",
      "DEBUG: send_request_body.complete\n",
      "DEBUG: receive_response_headers.started request=<Request [b'HEAD']>\n",
      "DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Sun, 20 Jul 2025 09:21:40 GMT'), (b'server', b'uvicorn'), (b'content-length', b'9054'), (b'content-type', b'text/html; charset=utf-8')])\n",
      "INFO: HTTP Request: HEAD http://127.0.0.1:7870/ \"HTTP/1.1 200 OK\"\n",
      "DEBUG: receive_response_body.started request=<Request [b'HEAD']>\n",
      "DEBUG: receive_response_body.complete\n",
      "DEBUG: response_closed.started\n",
      "DEBUG: response_closed.complete\n",
      "DEBUG: close.started\n",
      "DEBUG: close.complete\n",
      "DEBUG: https://huggingface.co:443 \"HEAD /api/telemetry/gradio/initiated HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7870\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1142b8d10>\n",
      "DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x11414ad50> server_hostname='api.gradio.app' timeout=3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7870/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: https://huggingface.co:443 \"HEAD /api/telemetry/gradio/launched HTTP/1.1\" 200 0\n",
      "DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1146fcd50>\n",
      "DEBUG: send_request_headers.started request=<Request [b'GET']>\n",
      "DEBUG: send_request_headers.complete\n",
      "DEBUG: send_request_body.started request=<Request [b'GET']>\n",
      "DEBUG: send_request_body.complete\n",
      "DEBUG: receive_response_headers.started request=<Request [b'GET']>\n",
      "DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 20 Jul 2025 09:21:41 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'21'), (b'Connection', b'keep-alive'), (b'Server', b'nginx/1.18.0'), (b'Access-Control-Allow-Origin', b'*')])\n",
      "INFO: HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "DEBUG: receive_response_body.started request=<Request [b'GET']>\n",
      "DEBUG: receive_response_body.complete\n",
      "DEBUG: response_closed.started\n",
      "DEBUG: response_closed.complete\n",
      "DEBUG: close.started\n",
      "DEBUG: close.complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import subprocess, os, sys\n",
    "import gradio as gr\n",
    "from urllib.parse import urlparse, urljoin\n",
    "\n",
    "\n",
    "# from urllib.parse import urljoin, urlparse\n",
    "# from scrapy.crawler import CrawlerRunner\n",
    "# from scrapy.utils.log import configure_logging\n",
    "# from twisted.internet import reactor, defer\n",
    "# import asyncio\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## Web Scraper\")\n",
    "    gr.Markdown(\"This is a simple web scraper that can be used to scrape investor relations pages.\")\n",
    "    \n",
    "    url = gr.Textbox(label=\"Enter URL\", placeholder=\"https://example.com\")\n",
    "    \n",
    "    status = gr.Textbox(label=\"Status\", interactive=False, value=\"Ready to scrape. Enter a URL and press Enter.\", lines=5)\n",
    "\n",
    "    def run_scraper(url):\n",
    "        # Run the spider as a subprocess\n",
    "        if not url.startswith(\"http\"):\n",
    "            url = \"http://\" + url\n",
    "        # Extract the domain from the URL\n",
    "        parsed_url = urlparse(url)\n",
    "        domain = parsed_url.netloc.replace(\"www.\", \"\")\n",
    "        if not domain:\n",
    "            return \"Invalid URL. Please enter a valid URL.\"\n",
    "        status.value = f\"Scraping {url}...\"\n",
    "        # Run the spider using subprocess\n",
    "        try:\n",
    "            result = subprocess.run([sys.executable, 'spider_runner.py', url, domain], check=True, text=True, capture_output=True)\n",
    "            status_value = f\"Scraping completed for {url}.\"\n",
    "            return result.stderr, status_value\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            status_value = f\"Error occurred: {e}\"\n",
    "            return f\"Error: {e}\", status_value\n",
    "    \n",
    "    output = gr.Textbox(label=\"Output\", interactive=False)\n",
    "    \n",
    "    url.submit(run_scraper, inputs=url, outputs=[output,status]) \n",
    "\n",
    "demo.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500a24c2",
   "metadata": {},
   "source": [
    "Crawling in Jupyter notebooks tends to crash the kernel as the CrawlerProcess' asyncio loop interferes with the Jupyter notebook's.\n",
    "Kudos to Claude for spotting this. I had to run the scraper as a subprocess in order to make it work. \n",
    "\n",
    "In a production environment it would run as a python script in a container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e0413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Jupyter notebooks - test the scraper\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "result = subprocess.run([\n",
    "    sys.executable, 'spider_runner.py',\n",
    "    'https://www.eurobank.gr/en/group/investor-relations',\n",
    "    'eurobank.gr'\n",
    "], capture_output=True, text=True)\n",
    "\n",
    "print(\"STDOUT:\")\n",
    "print(result.stdout)\n",
    "print(\"STDERR:\")\n",
    "print(result.stderr)\n",
    "print(f\"Return code: {result.returncode}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
